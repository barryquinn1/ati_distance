<!DOCTYPE html>
<html lang="en"><head>
<script src="indexx_files/libs/clipboard/clipboard.min.js"></script>
<script src="indexx_files/libs/quarto-html/tabby.min.js"></script>
<script src="indexx_files/libs/quarto-html/popper.min.js"></script>
<script src="indexx_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="indexx_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="indexx_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="indexx_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="indexx_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.450">

  <title>Distance metrics</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="indexx_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="indexx_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="indexx_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="mycssblend.css">
  <link href="indexx_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="indexx_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="indexx_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="indexx_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="img/title-slide.png" data-background-opacity="0.5" data-background-size="cover" class="quarto-title-block center">
  <h1 class="title">Distance metrics</h1>
  <p class="subtitle">How information theory can help solve real-world financial problems</p>

<div class="quarto-title-authors">
</div>

</section>
<section id="outline" class="slide level2 saltinline">
<h2>Outline</h2>
<ul>
<li>Distance metrics
<ul>
<li>Correlation based distance metrics</li>
</ul></li>
<li>Shannon‚Äôs entropy
<ul>
<li>Marginal, conditional, joint</li>
</ul></li>
<li>Experimental evidence</li>
<li>Financial problem investigation</li>
</ul>
</section>
<section id="distance-metrics" class="slide level2 saltinline small">
<h2>Distance Metrics</h2>
<ul>
<li>Many problems in finance require the clustering of variables or observations:</li>
</ul>
<ol type="1">
<li>Factor investing, relative value analysis (e.g., forming quality minus junk portfolios)</li>
<li>Risk management, portfolio construction (e.g., deriving the efficient frontier)</li>
<li>Dimensionality reduction (e.g., decomposing bond return drivers)</li>
<li>Modelling of multicollinear systems (e.g., computing p-values)</li>
</ol>
</section>
<section id="distance-metrics-1" class="slide level2 saltinline small">
<h2>Distance Metrics</h2>
<p>So Far We Have Studied‚Ä¶</p>
<p>‚Ä¢ The important numerical properties of the empirical correlation (and by extension, covariance) matrix.</p>
<p><strong>Critical Limitations of Correlation</strong></p>
<p>‚Ä¢ Despite its virtues, correlation suffers from several critical limitations as a measure of codependency.</p>
<p><strong>Overcoming These Limitations</strong></p>
<p>‚Ä¢ In this lecture, we will overcome these limitations by reviewing information theory concepts that underlie many modern marvels.</p>
<p><strong>Information Theory Concepts</strong></p>
<p>‚Ä¢ Internet, mobile phones, file compression, video streaming, and encryption.</p>
<p><strong>Why We Looked Beyond Correlation</strong></p>
<p>‚Ä¢ None of these inventions would have been possible if researchers had not looked beyond correlations to understand codependency.</p>
</section>
<section id="claude-shannons-entropy" class="slide level2">
<h2>Claude Shannon‚Äôs Entropy</h2>
<p>üîç <strong>Information Theory Applications in Finance</strong></p>
<p>‚Ä¢ As it turns out, information theory in general, and the concept of Shannon‚Äôs entropy in particular, also have useful applications in finance. üí°</p>
<p>‚Ä¢ The key idea behind entropy is to quantify the amount of uncertainty associated with a random variable. üîç</p>
<p>‚Ä¢ Information theory is also essential to ML, because the primary goal of many ML algorithms is to reduce the amount of uncertainty involved in the solution to a problem. üíØ</p>
<p>üëâ We will see how Shannon‚Äôs entropy, a key concept in information theory, can help solve real-world financial problems! üìà</p>
</section>
<section id="desirably-properties-of-a-distance-metric" class="slide level2">
<h2>Desirably properties of a distance metric</h2>
<ul>
<li>In mathematics, a distance function or metric is a generalisation of the concept of physical distance. A metric is a function that defines a distance between each pair of elements of a set.</li>
</ul>
<ol type="1">
<li>Non-negativity: <span class="math inline">\(d(x, y) \geq 0\)</span></li>
<li>Identity of indiscernibles: <span class="math inline">\(d(x, y) = 0\)</span> if and only if <span class="math inline">\(x = y\)</span></li>
<li>Symmetry: <span class="math inline">\(d(x, y) = d(y, x)\)</span></li>
<li>Triangle inequality: <span class="math inline">\(d(x, y) + d(y, z) \geq d(x, z)\)</span></li>
</ol>
</section>
<section id="correlation-is-not-a-metric" class="slide level2">
<h2>Correlation is not a metric</h2>
<p>Consider Two Random Vectors‚Ä¶</p>
<p>‚Ä¢ Let X and Y be two random vectors of size T, and a correlation estimate œÅ(X,Y), with the only requirement that œÉ(X,Y) = œÅ(X,Y)œÉ(X)œÉ(Y).</p>
<p>‚Ä¢ œÉ(X,Y) is the covariance between the two vectors.</p>
<p>‚Ä¢ œÉ(X) and œÉ(Y) are the standard deviations of X and Y, respectively.</p>
<p>Pearson‚Äôs Correlation‚Ä¶</p>
<p>‚Ä¢ Pearson‚Äôs correlation is one of several correlation estimates that satisfy these requirements.</p>
</section>
<section id="correlation-is-not-a-metric-1" class="slide level2">
<h2>Correlation is not a metric</h2>
<ul>
<li>Pearson‚Äôs correlation is a measure of the linear relationship between two variables.</li>
<li>It is a number between -1 and 1.</li>
<li>It does not have the properties of a distance metric.</li>
<li>Specifically, it does not satisfy the triangle inequality or non-negativity.</li>
</ul>
</section>
<section id="a-correlation-based-distance-metric" class="slide level2">
<h2>A correlation-based distance metric</h2>
<ul>
<li><p>The correlation-based distance metric is defined as: <span class="math display">\[d(x, y) = \sqrt{2(1 - \rho(x, y))}\]</span> where <span class="math inline">\(\rho(x, y)\)</span> is the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p></li>
<li><p>This metric does satisfy the properties of a distance metric.</p></li>
</ul>
</section>
<section id="proof" class="slide level2 small">
<h2>Proof</h2>
<p>üìù Euclidean Distance Definition</p>
<ol type="1">
<li>The Euclidean distance between two vectors is defined as:</li>
</ol>
<p><span class="math display">\[d\left(X,Y\right)=\sqrt{\sum_{t=1}^{T}\left(X_t-Y_t\right)^2}\]</span></p>
<p>üí° Z-Standardization</p>
<ol start="2" type="1">
<li>Z-standardise the vectors so that <span class="math inline">\(x = \left(X - \bar{X}\right)/\sigma\left(X\right)\)</span> and <span class="math inline">\(y = \left(Y - \bar{Y}\right)/\sigma\left(Y\right)\)</span>, where <span class="math inline">\(\bar{.}\)</span> is the mean value.</li>
</ol>
<p>üìà Correlation Derivation</p>
<ol start="3" type="1">
<li>We derive the Euclidean distance <span class="math inline">\(d\left(x,y\right)\)</span>:</li>
</ol>
<p><span class="math display">\[d\left(x,y\right) = \sqrt{\sum_{t=1}^{T}\left(x_t-y_t\right)^2} =
\sqrt{T+T=2T\sigma\left(x,y\right)} = \sqrt{4T}d+p(X,Y)\]</span></p>
<p>üîç Inheritance of True-Metric Properties</p>
<ol start="4" type="1">
<li>This implies that <span class="math inline">\(d_p(X,Y)\)</span> is a linear multiple of the Euclidean distance between the vectors <span class="math inline">\(\left\{X,Y \right\}\)</span> after z-standardization <span class="math inline">\(d(x,y)\)</span>, thus inheriting the true-metric properties of the Euclidean distance.</li>
</ol>
</section>
<section id="properties-of-metric-d_pxy" class="slide level2">
<h2>Properties of Metric <span class="math inline">\(d_p(x,y)\)</span></h2>
<p>üìù Normalisation</p>
<ol type="1">
<li>It is normalized, <span class="math inline">\(d_p(X,Y) \in[0,1]\)</span>, because <span class="math inline">\(\rho(X,Y) \in[-1,1]\)</span>.</li>
</ol>
<p>üîç Non-negativity Property</p>
<ol start="2" type="1">
<li>It deems more distant two random variables with negative correlation than two random variables with positive correlation, regardless of their absolute value.</li>
</ol>
<p>üí° Financial Applications</p>
<blockquote>
<p>This property is very useful in finance, for example, we may wish to build a long-only portfolio where holdings in negative-correlated securities can only offset risk and therefore should be treated as different for diversification purposes.</p>
</blockquote>
</section>
<section id="an-alternative-correlation-based-distance-metric-d_pxy" class="slide level2 small">
<h2>An Alternative Correlation-Based Distance Metric <span class="math inline">\(d_{|p|}(X,Y)\)</span></h2>
<div class="columns">
<div class="column">
<p>üìù Aim</p>
<ul>
<li>In a long-short portfolio, we often prefer to consider highly negatively correlated securities as similar, because the position sign can override the sign of the correlation. For that case, we can define an alternative normalized correlation-based distance metric:</li>
</ul>
<p><span class="math display">\[d_{|p|} = \sqrt{1 - | \rho(X,Y) |}\]</span></p>
<p>üí° Metric Definition</p>
<ul>
<li>This metric is defined as the square root of the absolute value of the correlation between the two vectors minus 1.</li>
</ul>
</div><div class="column">
<p>üîç Advantages</p>
<div class="saltinline">
<ul>
<li>It treats highly negatively correlated securities as similar, which can be useful in a long-short portfolio.</li>
<li>It is based on the absolute value of the correlation, which can be more intuitive than the traditional Euclidean distance metric.</li>
<li>It is normalized, meaning that it has a minimum value of 0 and a maximum value of 1, which can make it easier to interpret.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="entropy-what-is-it" class="slide level2">
<h2>Entropy: What is it?</h2>
<ul>
<li>Entropy is a measure of uncertainty or randomness in a random variable.</li>
<li>It is a measure of the average amount of information produced by a stochastic source of data.</li>
<li>It is a measure of the unpredictability of information content.</li>
<li>It is a measure of the disorder in a system.</li>
<li>In finance, entropy can be used to measure the uncertainty in the returns of a stock or a portfolio.</li>
</ul>
</section>
<section id="entropy-in-quantitative-finance" class="slide level2 small">
<h2>Entropy in Quantitative Finance</h2>
<ul>
<li>Exploiting entropy is not going to untie the knots, but it can help us solve problems that arise when using the conventional correlation measure in quantitative finance.</li>
<li>The concept of correlation has three important limitations:</li>
</ul>
<ol type="1">
<li>Firstly, it quantifies the linear codependency between two random variables, but neglects nonlinear relationships.</li>
<li>Secondly, correlation is highly influenced by outliers.</li>
<li>Finally, its application beyond the multivariate normal case is questionable.</li>
</ol>
</section>
<section id="entropy-in-quantitative-finance-1" class="slide level2 small">
<h2>Entropy in Quantitative Finance</h2>
<ul>
<li>To overcome these limitations, we need to introduce a few information-theoretic concepts, such as:
<ul>
<li>Entropy, which measures the amount of uncertainty or randomness in a system.</li>
<li>Mutual information, which quantifies the amount of information that one random variable contains about another.</li>
<li>Conditional entropy, which measures the amount of uncertainty or randomness in one random variable given the value of another.</li>
<li>Jensen‚Äôs inequality, which provides a lower bound on the entropy of a random variable.</li>
<li>The KL divergence, which measures the difference between two probability distributions.</li>
</ul></li>
</ul>
</section>
<section id="entropy-and-the-challenge-of-measuring-accuracy" class="slide level2">
<h2>Entropy and the challenge of measuring accuracy</h2>
<ul>
<li>Information theory provides a natural measurement scale for distance between two probability distributions</li>
<li>Need to establish deviance as an approximation of relative distance from perfect accuracy</li>
</ul>
</section>
<section id="desirable-properties-of-good-uncertainty-measure" class="slide level2">
<h2>Desirable properties of good uncertainty measure</h2>
<ul>
<li>Measure should be continuous</li>
<li>Should increase as the number of possible events increases</li>
<li>Should be additive</li>
</ul>
</section>
<section id="information-entropy" class="slide level2">
<h2>Information entropy</h2>
<ul>
<li>Definition: -E(log(p_i))= -‚àë(p_i) log(p_i)</li>
<li>Intuitive explanation: uncertainty contained in a probability distribution is the average log-probability of an event</li>
<li>Viewed as the expected value of these surprises</li>
<li>Accepted as a useful measure of uncertainty not because of premises that lead to it, but rather because it has turned out to be so useful and productive</li>
</ul>
</section>
<section id="practical-applications-of-entropy" class="slide level2">
<h2>Practical applications of entropy</h2>
<ul>
<li>Lets calculate the information entropy for the weather tomorrow</li>
<li>Suppose the true probabilities of rain and shine are <span class="math inline">\(p_1=0.3\)</span> and <span class="math inline">\(p_2=0.7\)</span>, respectively. Then: <span class="math display">\[H(p)=-(p_1 log(p_1)+p_2 log(p_2)) \approx 0.61\]</span></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.3</span>,<span class="fl">0.7</span>)</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="sc">-</span><span class="fu">sum</span>(p<span class="sc">*</span><span class="fu">log</span>(p))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6108643</code></pre>
</div>
</div>
</section>
<section id="practical-applications-of-entropy-1" class="slide level2">
<h2>Practical applications of entropy</h2>
<ul>
<li>Suppose instead we live in Abu Dhabi</li>
<li>Then the probabilities of rain and shine might be more like <span class="math inline">\(p_1=0.01\)</span> and <span class="math inline">\(p_2=0.99\)</span></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.01</span>,<span class="fl">0.99</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="sc">-</span><span class="fu">sum</span>(p<span class="sc">*</span><span class="fu">log</span>(p))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.05600153</code></pre>
</div>
</div>
</section>
<section id="practical-applications-of-entropy-2" class="slide level2">
<h2>Practical applications of entropy</h2>
<ul>
<li>now the entropy would be approximately 0.06</li>
<li>Why has the uncertainty decreased?</li>
</ul>
<div class="fragment">
<ul>
<li>Because in Abu Dhabi it hardly ever rains.</li>
<li>Therefore there‚Äôs much less uncertainty about any given day, compared to a place in which it rains 30% of the time.</li>
<li>It‚Äôs in this way that information entropy measures the uncertainty inherent in a distribution of events.</li>
</ul>
</div>
</section>
<section id="entropy-and-forecasting-complexity" class="slide level2">
<h2>Entropy and forecasting complexity</h2>
<ul>
<li>Similarly, if we add another kind of event to the distribution,forecasting into winter, so also predicting snow, entropy tends to increase, due the added dimensionality of the prediction problem.</li>
<li>Similarly, if we add another kind of event to the distribution, .blue[forecasting into winter, so also predicting snow], entropy tends to increase, due the added dimensionality of the prediction problem.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>p<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fl">0.7</span>,<span class="fl">0.15</span>,<span class="fl">0.15</span>)</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="sc">-</span><span class="fu">sum</span>(p<span class="sc">*</span><span class="fu">log</span>(p))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8188085</code></pre>
</div>
</div>
<ul>
<li>Then entropy is about 0.82</li>
</ul>
</section>
<section id="entropy-definition" class="slide level2">
<h2>Entropy Definition</h2>
<ul>
<li>The definition of entropy is <span class="math inline">\(-\sum_{x \in S} p(x) log(p(x))\)</span>, where <span class="math inline">\(S\)</span> is the sample space of the random variable.</li>
<li>This formula assumes that the events are mutually exclusive and exhaustive, which may not always be the case in real-world scenarios.</li>
</ul>
</section>
<section id="logarithms" class="slide level2">
<h2>Logarithms</h2>
<ul>
<li>The logarithms used in entropy calculations can be either natural logs (base e) or binary logs (base 2).</li>
<li>However, it‚Äôs important to note that different bases can lead to different interpretations of entropy.</li>
<li>When comparing entropies across different random variables, it‚Äôs essential to use the same base.</li>
</ul>
</section>
<section id="zero-probability-events" class="slide level2">
<h2>Zero Probability Events</h2>
<ul>
<li><span class="math inline">\(log(0) = \infty\)</span>, which means that events with probability 0 contribute nothing to the entropy.</li>
<li>To avoid any inconsistencies, we set <span class="math inline">\(log(0) = 0\)</span> when computing entropy.</li>
</ul>
</section>
<section id="joint-entropy" class="slide level2">
<h2>Joint Entropy</h2>
<ul>
<li>The joint entropy of two random variables X and Y is <span class="math inline">\(-\sum_{x,y \in S_X,S_Y} p(x,y) log(p(x,y))\)</span>, where <span class="math inline">\(S_X\)</span> and <span class="math inline">\(S_Y\)</span> are the sample spaces of X and Y, respectively.</li>
<li>This formula assumes that the events are mutually exclusive and exhaustive.</li>
</ul>
</section>
<section id="properties-of-joint-entropy" class="slide level2">
<h2>Properties of Joint Entropy</h2>
<ul>
<li>Non-negativity: <span class="math inline">\(H(X,Y) \ge 0\)</span>.</li>
<li>Symmetry: <span class="math inline">\(H(X,Y) = H(Y,X)\)</span>.</li>
<li>Greater than individual entropies: <span class="math inline">\(H(X,Y) \ge max(H(X),H(Y))\)</span>.</li>
<li>Less than or equal to the sum of individual entropies: <span class="math inline">\(H(X,Y) \le H(X) + H(Y)\)</span>.</li>
</ul>
<p>Certainly! Here‚Äôs how you could structure the explanation of calculating joint entropy between two financial assets using R, formatted as a series of Markdown slides for a presentation.</p>
</section>
<section id="calculating-joint-entropy-in-finance-with-r" class="slide level2">
<h2>Calculating Joint Entropy in Finance with R</h2>
<ul>
<li>Joint entropy quantifies the uncertainty in a joint distribution of two random variables.</li>
<li>Useful for analyzing the combined behavior of financial market variables.</li>
<li>We‚Äôll demonstrate using simulated asset returns.</li>
</ul>
</section>
<section id="setup-in-r" class="slide level2">
<h2>Setup in R</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Ensure the infotheo package is installed and loaded</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">"infotheo"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) <span class="fu">install.packages</span>(<span class="st">"infotheo"</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="fu">library</span>(infotheo)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="simulating-asset-returns" class="slide level2">
<h2>Simulating Asset Returns</h2>
<ul>
<li>Simulate daily returns for two hypothetical financial assets.</li>
<li>Assume normally distributed returns for simplicity.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co"># Ensuring reproducibility</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>returns_asset1 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="fl">0.001</span>, <span class="at">sd =</span> <span class="fl">0.01</span>) <span class="co"># Asset 1 returns</span></span>
<span id="cb8-3"><a href="#cb8-3"></a>returns_asset2 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="fl">0.001</span>, <span class="at">sd =</span> <span class="fl">0.02</span>) <span class="co"># Asset 2 returns</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="discretizing-returns" class="slide level2">
<h2>Discretizing Returns</h2>
<ul>
<li>Discretization is necessary for calculating entropy.</li>
<li>The choice of bins is crucial and can affect the outcome.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>bins <span class="ot">=</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fu">min</span>(<span class="fu">c</span>(returns_asset1, returns_asset2)), <span class="at">to =</span> <span class="fu">max</span>(<span class="fu">c</span>(returns_asset1, returns_asset2)), <span class="at">length.out =</span> <span class="dv">10</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a>discrete_returns1 <span class="ot">=</span> <span class="fu">cut</span>(returns_asset1, <span class="at">breaks =</span> bins, <span class="at">labels =</span> <span class="cn">FALSE</span>)</span>
<span id="cb9-3"><a href="#cb9-3"></a>discrete_returns2 <span class="ot">=</span> <span class="fu">cut</span>(returns_asset2, <span class="at">breaks =</span> bins, <span class="at">labels =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="calculating-joint-entropy" class="slide level2">
<h2>Calculating Joint Entropy</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># Calculate mutual information (and hence joint entropy)</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>joint_entropy <span class="ot">=</span> <span class="fu">mutinformation</span>(discrete_returns1, discrete_returns2, <span class="at">method =</span> <span class="st">"emp"</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Joint entropy (natural log base):"</span>, joint_entropy))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Joint entropy (natural log base): 0.194283857148803"</code></pre>
</div>
</div>
<ul>
<li>If you specifically need the entropy value in bits, you can manually convert the output from natural logarithm to log base 2 by dividing the result by <code>log(2)</code>:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="co"># Convert the result to bits</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>joint_entropy_bits <span class="ot">=</span> joint_entropy <span class="sc">/</span> <span class="fu">log</span>(<span class="dv">2</span>)</span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Joint entropy (in bits):"</span>, joint_entropy_bits))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Joint entropy (in bits): 0.280292357233359"</code></pre>
</div>
</div>
<ul>
<li>Joint entropy provides insights into the information contained within the combined behavior of two financial assets.</li>
<li>This example used simulated data and basic discretization for illustration.</li>
</ul>
</section>
<section id="economic-interpretation-of-joint-entropy-in-finance" class="slide level2">
<h2>Economic Interpretation of Joint Entropy in Finance</h2>
<ul>
<li><strong>Complexity of Asset Relationships:</strong> A joint entropy of 0.280292357233359 bits suggests a moderate level of unpredictability and complexity in the relationship between the two assets‚Äô returns. This indicates some degree of informational efficiency but also room for diversification.</li>
<li><strong>Market Behaviour:</strong> The specific value reflects the combined information content and interdependency of the assets under study, implying that while they share some information, each still possesses unique characteristics.</li>
</ul>
</section>
<section id="strategic-implications" class="slide level2">
<h2>Strategic Implications</h2>
<ul>
<li><strong>Diversification Benefits:</strong> The calculated joint entropy value points towards potential diversification benefits. It suggests that the assets‚Äô price movements are not perfectly correlated, which can help in reducing overall portfolio volatility.</li>
<li><strong>Risk Management and Investment Decisions:</strong> This joint entropy value should inform risk management strategies by highlighting the importance of considering the complexity and predictability of asset returns. Investors should use this alongside other analyses for a comprehensive investment strategy.</li>
</ul>
</section>
<section id="understanding-entropy-in-finance" class="slide level2">
<h2>Understanding Entropy in Finance</h2>
<ul>
<li><strong>Conditional Entropy:</strong>
<ul>
<li>Formula: (H(X|Y) = H(X,Y) - H(Y))</li>
<li>Represents the expected uncertainty in one variable ((X)) given the knowledge of another ((Y)). Essential for modeling predictability in financial markets.</li>
</ul></li>
<li><strong>Maximum Entropy (MaxEnt):</strong>
<ul>
<li>Approach: Maximize (H(X)) subject to known constraints.</li>
<li>Identifies the least presumptive probability distributions based on known information, central to Bayesian inference and machine learning.</li>
</ul></li>
</ul>
</section>
<section id="divergence-and-its-financial-significance" class="slide level2">
<h2>Divergence and Its Financial Significance</h2>
<ul>
<li><strong>Kullback-Leibler (KL) Divergence:</strong>
<ul>
<li>Formula: (D_{KL}(p, q) = _i p_i ())</li>
<li>Measures the extra uncertainty induced when using distribution (q) to approximate (p), crucial for assessing model accuracy.</li>
</ul></li>
<li><strong>Cross-Entropy:</strong>
<ul>
<li>Formula: (H_c(p, q) = -_{xS_X}p(x) (q(x)))</li>
<li>Highlights the discrepancy between the true distribution ((p)) and the predicted one ((q)), essential for evaluating classification models in finance.</li>
</ul></li>
</ul>
</section>
<section id="mutual-information-and-strategic-insights" class="slide level2">
<h2>Mutual Information and Strategic Insights</h2>
<ul>
<li><strong>Mutual Information:</strong>
<ul>
<li>Formula: (I(X;Y) = H(X) - H(X|Y) = H(X) + H(Y) - H(X,Y))</li>
<li>Quantifies the informational gain in variable (X) from knowing (Y), demonstrating the value of shared information between financial variables for strategic decision-making.</li>
</ul></li>
</ul>
</section>
<section id="implications-for-financial-machine-learning" class="slide level2">
<h2>Implications for Financial Machine Learning</h2>
<ul>
<li><strong>Model Selection and Evaluation:</strong> Theoretical concepts like divergence and cross-entropy help in selecting and evaluating models based on their fidelity to true market behaviors and predictive capabilities.</li>
<li><strong>Strategic Decision-Making:</strong> Insights from mutual information and maximum entropy support financial practitioners in crafting robust investment strategies, managing risk, and optimizing portfolios with a principled understanding of market uncertainty.</li>
</ul>
</section>
<section id="practical-financial-example" class="slide level2">
<h2>Practical financial example</h2>
<ul>
<li>First, we install and load the <code>quantmod</code> package, then download stock data for AAPL and MSFT.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="co">#install.packages("quantmod")</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="fu">library</span>(quantmod)</span>
<span id="cb14-3"><a href="#cb14-3"></a></span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="co"># Specify the stocks and time period</span></span>
<span id="cb14-5"><a href="#cb14-5"></a>stocks <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"AAPL"</span>, <span class="st">"MSFT"</span>)</span>
<span id="cb14-6"><a href="#cb14-6"></a>start_date <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="st">"2020-01-01"</span>)</span>
<span id="cb14-7"><a href="#cb14-7"></a>end_date <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="st">"2020-12-31"</span>)</span>
<span id="cb14-8"><a href="#cb14-8"></a></span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="co"># Download stock data</span></span>
<span id="cb14-10"><a href="#cb14-10"></a><span class="fu">getSymbols</span>(stocks, <span class="at">from=</span>start_date, <span class="at">to=</span>end_date, <span class="at">auto.assign =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "AAPL" "MSFT"</code></pre>
</div>
</div>
</section>
<section id="calculate-daily-returns" class="slide level2">
<h2>Calculate Daily Returns</h2>
<p>Next, we calculate the daily returns for each stock.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>returns_aapl <span class="ot">&lt;-</span> <span class="fu">dailyReturn</span>(AAPL)</span>
<span id="cb16-2"><a href="#cb16-2"></a>returns_msft <span class="ot">&lt;-</span> <span class="fu">dailyReturn</span>(MSFT)</span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="co">#add both plots together</span></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb16-5"><a href="#cb16-5"></a><span class="fu">plot</span>(returns_aapl, <span class="at">main =</span> <span class="st">"AAPL Daily Returns"</span>)</span>
<span id="cb16-6"><a href="#cb16-6"></a><span class="fu">plot</span>(returns_msft, <span class="at">main =</span> <span class="st">"MSFT Daily Returns"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="indexx_files/figure-revealjs/unnamed-chunk-10-1.png" width="960" class="r-stretch"><div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Linear correlation (in bits):"</span>, <span class="fu">cor</span>(returns_aapl,returns_msft)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Linear correlation (in bits): 0.839278219328719"</code></pre>
</div>
</div>
</section>
<section id="discretize-returns-and-calculate-information-measures" class="slide level2">
<h2>Discretize Returns and Calculate Information Measures</h2>
<p>To apply the <code>infotheo</code> functions, we need to discretize the returns. Then, we calculate the conditional entropy and mutual information.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="fu">library</span>(infotheo)</span>
<span id="cb19-2"><a href="#cb19-2"></a></span>
<span id="cb19-3"><a href="#cb19-3"></a><span class="co"># Discretise returns</span></span>
<span id="cb19-4"><a href="#cb19-4"></a>discretized_aapl <span class="ot">&lt;-</span> <span class="fu">discretize</span>(<span class="fu">as.numeric</span>(returns_aapl))</span>
<span id="cb19-5"><a href="#cb19-5"></a>discretized_msft <span class="ot">&lt;-</span> <span class="fu">discretize</span>(<span class="fu">as.numeric</span>(returns_msft))</span>
<span id="cb19-6"><a href="#cb19-6"></a></span>
<span id="cb19-7"><a href="#cb19-7"></a><span class="co"># Mutual Information between AAPL and MSFT returns</span></span>
<span id="cb19-8"><a href="#cb19-8"></a>mutual_info <span class="ot">&lt;-</span> <span class="fu">mutinformation</span>(discretized_aapl, discretized_msft, <span class="at">method =</span> <span class="st">"emp"</span>)</span>
<span id="cb19-9"><a href="#cb19-9"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Mutual Information between AAPL and MSFT:"</span>, mutual_info))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Mutual Information between AAPL and MSFT: 0.516904960511519"</code></pre>
</div>
</div>
</section>
<section id="variation-of-information" class="slide level2">
<h2>Variation of Information</h2>
<ul>
<li>The Variation of Information (VI) measure, also known as shared information distance, is a metric used in information theory to quantify the distance or dissimilarity between two random variables or between two clusterings.</li>
<li>It combines the concepts of mutual information and entropy to measure how much two variables or clusterings differ in terms of their information content.</li>
</ul>
</section>
<section id="overview-of-variation-of-information-vi" class="slide level2">
<h2>Overview of Variation of Information (VI)</h2>
<ul>
<li><strong>Definition:</strong> A metric that quantifies the dissimilarity between two random variables or clusterings by combining mutual information (I) and entropy (H).</li>
<li><strong>Formula:</strong> (VI(X, Y) = H(X) + H(Y) - 2I(X; Y))</li>
<li><strong>Interpretation:</strong> Measures the total amount of uncertainty or information that is unique to each of the variables (X) and (Y), not shared between them.</li>
</ul>
</section>
<section id="significance-in-finance" class="slide level2">
<h2>Significance in Finance</h2>
<ul>
<li><strong>Cluster Analysis:</strong> Used to evaluate the similarity between different financial market segmentations or clustering of assets based on returns, volatility, or other characteristics.</li>
<li><strong>Time Series Analysis:</strong> Helps in comparing the informational content of different financial time series, such as stock prices or economic indicators.</li>
<li><strong>Risk Management:</strong> Assists in identifying diversification opportunities by quantifying the dissimilarity in information content between asset returns.</li>
</ul>
</section>
<section id="applications" class="slide level2">
<h2>Applications</h2>
<ul>
<li><strong>Portfolio Optimization:</strong> Analyzing the variation of information between asset returns to optimize portfolio diversification and risk-adjusted returns.</li>
<li><strong>Market Segmentation:</strong> Evaluating the effectiveness of market segmentation strategies by measuring the dissimilarity in information content across segments.</li>
<li><strong>Economic Analysis:</strong> Comparing economic indicators to understand the unique and shared information contributing to economic forecasts.</li>
</ul>
</section>
<section id="benefits-and-challenges" class="slide level2">
<h2>Benefits and Challenges</h2>
<div class="columns">
<div class="column">
<h4 id="benefits">Benefits</h4>
<ul>
<li><strong>Quantitative Measure:</strong> Provides a clear, quantitative metric to assess dissimilarity in information content.</li>
<li><strong>Insightful:</strong> Offers deeper insights into the structure and dynamics of financial markets.</li>
<li><strong>Decision Support:</strong> Aids in making informed decisions by highlighting differences in informational content between variables.</li>
</ul>
</div><div class="column">
<h4 id="challenges">Challenges</h4>
<ul>
<li><strong>Data Intensive:</strong> Requires comprehensive data for accurate calculation and interpretation.</li>
<li><strong>Complexity:</strong> Understanding and applying VI can be complex, requiring a solid foundation in information theory.</li>
<li><strong>Interpretation:</strong> Interpreting the results of VI analysis in the context of financial decision-making can be challenging.</li>
</ul>
<hr>
</div>
</div>
</section>
<section id="tldr" class="slide level2 small">
<h2>TL;DR</h2>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 15%">
<col style="width: 17%">
<col style="width: 32%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Definition</th>
<th>Relationship</th>
<th>Applications in Finance</th>
<th>Metric Properties</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Entropy (H)</td>
<td>Measures the uncertainty or unpredictability of a variable‚Äôs outcome.</td>
<td>Fundamental to all other metrics as a measure of uncertainty.</td>
<td>Quantifying the unpredictability of financial variables such as asset returns, market volatility.</td>
<td><strong>No</strong>, entropy is not a distance measure and does not satisfy metric properties.</td>
</tr>
<tr class="even">
<td>Mutual Information (I)</td>
<td>Measures the amount of information shared between two variables; how much knowing one reduces uncertainty about the other.</td>
<td>Relates to entropy by quantifying the reduction in uncertainty.</td>
<td>Analyzing dependencies between financial variables, identifying market trends.</td>
<td><strong>No</strong>, mutual information is not a distance measure; it lacks symmetry and the triangle inequality for distances.</td>
</tr>
<tr class="odd">
<td>Conditional Entropy (H(X|Y))</td>
<td>Quantifies the remaining uncertainty in one variable when the state of another is known.</td>
<td>Derived from entropy, showing the reduction in uncertainty given another variable.</td>
<td>Assessing predictability of financial variables given others.</td>
<td><strong>No</strong>, conditional entropy is directional and does not satisfy symmetry or the triangle inequality.</td>
</tr>
<tr class="even">
<td>Cross-Entropy (Hc)</td>
<td>Measures the expected number of bits needed to identify an event from a set, based on a different probability distribution.</td>
<td>Incorporates KL divergence when comparing two distributions.</td>
<td>Evaluating performance of predictive models in finance.</td>
<td><strong>No</strong>, cross-entropy is not symmetric and does not satisfy the triangle inequality.</td>
</tr>
<tr class="odd">
<td>Kullback-Leibler Divergence (D_{KL})</td>
<td>Quantifies the difference between two probability distributions.</td>
<td>Measures the information gain from one distribution to another.</td>
<td>Measuring the discrepancy between model predictions and actual data.</td>
<td><strong>No</strong>, KL divergence is not symmetric and does not satisfy the triangle inequality.</td>
</tr>
<tr class="even">
<td>Variation of Information (VI)</td>
<td>A metric to quantify the dissimilarity between two random variables or clusterings.</td>
<td>Combines entropy and mutual information to measure total unique information.</td>
<td>Comparing financial market segmentations, understanding diversification.</td>
<td><strong>Yes</strong>, variation of information is a true metric as it satisfies non-negativity, identity of indiscernibles, symmetry, and the triangle inequality.</td>
</tr>
</tbody>
</table>
</section>
<section id="experimental-evidence" class="slide level2">
<h2>Experimental evidence</h2>
<p>To calculate the Variation of Information (VI) in R and compare it with linear correlation, especially emphasizing the differences in detecting non-linear relationships, we‚Äôll first simulate data to create an exaggerated non-linear relationship. Then, we‚Äôll calculate both the Pearson correlation coefficient (a measure of linear correlation) and the Variation of Information.</p>
<p>First, let‚Äôs simulate the data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co"># Ensure reproducibility</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb21-3"><a href="#cb21-3"></a>y <span class="ot">&lt;-</span> <span class="fu">sin</span>(x)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(x), <span class="at">sd =</span> <span class="fl">0.1</span>) <span class="co"># Non-linear relationship with added noise</span></span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="fu">plot</span>(x, y, <span class="at">main =</span> <span class="st">"Simulated Non-linear Relationship"</span>, <span class="at">xlab =</span> <span class="st">"X"</span>, <span class="at">ylab =</span> <span class="st">"Y"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="indexx_files/figure-revealjs/unnamed-chunk-13-1.png" width="960" class="r-stretch"><h3 id="calculating-pearson-correlation-in-r">Calculating Pearson Correlation in R</h3>
<p>The Pearson correlation can be directly calculated using the <code>cor()</code> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a>linear_correlation <span class="ot">&lt;-</span> <span class="fu">cor</span>(x, y)</span>
<span id="cb22-2"><a href="#cb22-2"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Linear Correlation:"</span>, linear_correlation))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Linear Correlation: -0.00696311389621414"</code></pre>
</div>
</div>
<h3 id="calculating-variation-of-information-in-r">Calculating Variation of Information in R</h3>
<p>Calculating the Variation of Information (VI) in R for continuous variables directly is not as straightforward because it typically requires the variables to be discretized or involves estimating their joint and individual entropies. Since there‚Äôs no built-in function for VI in base R or common packages, we‚Äôll need to implement it. This involves discretizing the data, calculating the entropies, and then using the VI formula.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a><span class="fu">library</span>(entropy) <span class="co"># Load the infotheo package for entropy and mutual information calculations</span></span>
<span id="cb24-2"><a href="#cb24-2"></a>x_disc <span class="ot">&lt;-</span> <span class="fu">discretize</span>(x,<span class="at">numBins =</span> <span class="dv">20</span>) <span class="co"># Discretize x into 10 bins</span></span>
<span id="cb24-3"><a href="#cb24-3"></a>y_disc <span class="ot">&lt;-</span> <span class="fu">discretize</span>(y, <span class="at">numBins=</span><span class="dv">20</span>) <span class="co"># Discretize y into 10 bins</span></span>
<span id="cb24-4"><a href="#cb24-4"></a></span>
<span id="cb24-5"><a href="#cb24-5"></a><span class="co"># Convert discretized data to numeric indices</span></span>
<span id="cb24-6"><a href="#cb24-6"></a>x_bins <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">factor</span>(x_disc))</span>
<span id="cb24-7"><a href="#cb24-7"></a>y_bins <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">factor</span>(y_disc))</span>
<span id="cb24-8"><a href="#cb24-8"></a></span>
<span id="cb24-9"><a href="#cb24-9"></a><span class="co"># Create contingency table for joint distribution</span></span>
<span id="cb24-10"><a href="#cb24-10"></a>joint_distribution <span class="ot">&lt;-</span> <span class="fu">table</span>(x_bins, y_bins)</span>
<span id="cb24-11"><a href="#cb24-11"></a></span>
<span id="cb24-12"><a href="#cb24-12"></a><span class="co"># Calculate individual entropies</span></span>
<span id="cb24-13"><a href="#cb24-13"></a>H_x <span class="ot">&lt;-</span> <span class="fu">entropy</span>(<span class="fu">table</span>(x_bins))</span>
<span id="cb24-14"><a href="#cb24-14"></a>H_y <span class="ot">&lt;-</span> <span class="fu">entropy</span>(<span class="fu">table</span>(y_bins))</span>
<span id="cb24-15"><a href="#cb24-15"></a></span>
<span id="cb24-16"><a href="#cb24-16"></a><span class="co"># Calculate joint entropy</span></span>
<span id="cb24-17"><a href="#cb24-17"></a>H_xy <span class="ot">&lt;-</span> <span class="fu">entropy</span>(joint_distribution)</span>
<span id="cb24-18"><a href="#cb24-18"></a></span>
<span id="cb24-19"><a href="#cb24-19"></a><span class="co"># Calculate mutual information</span></span>
<span id="cb24-20"><a href="#cb24-20"></a>I_xy <span class="ot">&lt;-</span> H_x <span class="sc">+</span> H_y <span class="sc">-</span> H_xy</span>
<span id="cb24-21"><a href="#cb24-21"></a></span>
<span id="cb24-22"><a href="#cb24-22"></a><span class="co"># Calculate Variation of Information</span></span>
<span id="cb24-23"><a href="#cb24-23"></a>VI <span class="ot">&lt;-</span> H_x <span class="sc">+</span> H_y <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> I_xy</span>
<span id="cb24-24"><a href="#cb24-24"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Variation of Information:"</span>, VI))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Variation of Information: 2.23006570879938"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="co"># For the Pearson correlation, no change is needed</span></span>
<span id="cb26-2"><a href="#cb26-2"></a>linear_correlation <span class="ot">&lt;-</span> <span class="fu">cor</span>(x, y)</span>
<span id="cb26-3"><a href="#cb26-3"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Linear Correlation:"</span>, linear_correlation))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Linear Correlation: -0.00696311389621414"</code></pre>
</div>
</div>
</section>
<section id="normalized-variation-of-information" class="slide level2">
<h2>Normalized Variation of Information</h2>
<ul>
<li><p>One common approach is to normalize VI by the joint entropy H(X,Y)H(X,Y) or by the sum of the individual entropies H(X)+H(Y)H(X)+H(Y), depending on the context and what aspect of the data you‚Äôre most interested in:</p></li>
<li><p>Normalized VI=VI(X,Y)H(X)+H(Y)Normalized VI=H(X)+H(Y)VI(X,Y)‚Äã</p></li>
<li><p>This normalization ensures that the VI lies between 0 and 1, where 0 indicates that the two variables share all their information (identical distributions) and 1 indicates that the two variables share no information.</p></li>
</ul>
</section>
<section id="normalized-variation-of-information-in-r" class="slide level2">
<h2>Normalized Variation of Information in R</h2>
<ul>
<li>Let‚Äôs continue from the previous example, assuming <code>H_x</code>, <code>H_y</code>, and <code>I_xy</code> (mutual information) have already been calculated:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Assuming H_x, H_y, and I_xy have already been calculated</span></span>
<span id="cb28-2"><a href="#cb28-2"></a></span>
<span id="cb28-3"><a href="#cb28-3"></a><span class="co"># Calculate Variation of Information (VI) again for clarity</span></span>
<span id="cb28-4"><a href="#cb28-4"></a>VI <span class="ot">&lt;-</span> H_x <span class="sc">+</span> H_y <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> I_xy</span>
<span id="cb28-5"><a href="#cb28-5"></a></span>
<span id="cb28-6"><a href="#cb28-6"></a><span class="co"># Normalize VI to range between 0 and 1</span></span>
<span id="cb28-7"><a href="#cb28-7"></a><span class="co"># Normalized VI is VI divided by the sum of the individual entropies (max possible VI)</span></span>
<span id="cb28-8"><a href="#cb28-8"></a>Normalized_VI <span class="ot">&lt;-</span> VI <span class="sc">/</span> (H_x <span class="sc">+</span> H_y)</span>
<span id="cb28-9"><a href="#cb28-9"></a></span>
<span id="cb28-10"><a href="#cb28-10"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Variation of Information:"</span>, VI))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Variation of Information: 2.23006570879938"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Normalized Variation of Information:"</span>, Normalized_VI))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Normalized Variation of Information: 0.896160537565619"</code></pre>
</div>
</div>
<p>::: ::: column #### Interpretation - <strong>Variation of Information (VI):</strong> Provides a measure of the total unique and shared information between two variables. A lower value indicates more shared information, while a higher value indicates less shared information and more uniqueness. - <strong>Normalized Variation of Information:</strong> Adjusts VI into a 0 to 1 scale, where 0 indicates perfect agreement (identical information content) and 1 indicates complete disagreement (no shared information). This normalization makes it easier to interpret the degree of dissimilarity between the variables. ::: :::</p>
</section>
<section id="practical-advice" class="slide level2">
<h2>Practical Advice</h2>
<ul>
<li>This normalization technique does not change the essence of what VI measures but scales its output to a more interpretable range, especially useful when comparing across different pairs of variables or datasets. Remember, this normalized VI still does not indicate directionality or the type of relationship (linear or non-linear) between the variables, unlike correlation coefficients.</li>
</ul>
</section>
<section id="explaining-the-results" class="slide level2">
<h2>Explaining the Results</h2>
<ul>
<li><p>This example simulates a non-linear relationship between (x) and (y), calculates the linear correlation to show its limitation in capturing non-linear dependencies, and calculates the Variation of Information, which is not limited to linear relationships and can capture the total amount of shared and unique information between the variables.</p></li>
<li><p>The Pearson correlation coefficient might be low or not significant because it only measures linear relationships. In contrast, the Variation of Information could be higher, reflecting the complexity of the non-linear relationship that the linear correlation fails to capture.</p></li>
</ul>
</section>
<section id="limitation-and-consideration" class="slide level2">
<h2>Limitation and Consideration</h2>
<ul>
<li>When working with continuous data, the discretization process can significantly impact the results of information-theoretic measures. The choice of binning method (‚Äúfd‚Äù in this case) and the number of bins can influence the entropy and mutual information calculations, and thereby the Variation of Information. It‚Äôs crucial to experiment with these parameters and understand their effects on your analysis.</li>
</ul>

<img src="img/qbslogo.png" class="slide-logo r-stretch"><div class="footer footer-default">
<p>AI &amp; Trading</p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="indexx_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="indexx_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="indexx_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="indexx_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="indexx_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="indexx_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="indexx_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="indexx_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="indexx_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="indexx_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>